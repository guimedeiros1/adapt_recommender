{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/rating_explicit_only.csv', sep=',', skipinitialspace=True)\n",
    "\n",
    "n_users = df.learner_id.unique().shape[0]\n",
    "n_items = df.movie_id.unique().shape[0]\n",
    "\n",
    "print('Number of users = ' + str(n_users) + ' | Number of movies = ' + str(n_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_max = df.sort_values(by=['learner_id'], ascending=False).head(n=1)\n",
    "\n",
    "id_max = int(id_max.learner_id)\n",
    "\n",
    "print('The maximum learner_id in this list is= ' + str(id_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mv = pd.read_csv('../data/movie.csv', sep=',', skipinitialspace=True)\n",
    "\n",
    "df['movie_knowledge_area'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrn = pd.read_csv('../data/learner.csv', sep=',', skipinitialspace=True)\n",
    "\n",
    "lrn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy the value of knowledge area from movies.csv\n",
    "for index, row in df.iterrows():\n",
    "    target_mv = mv.loc[mv.id == row.movie_id]\n",
    "    df.movie_knowledge_area.iloc[index] = target_mv.movie_knowledge_area.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rating mean grouped by movie knowledge area\n",
    "\n",
    "mean_ratings = df.groupby(['movie_knowledge_area'])['rating'].mean()\n",
    "\n",
    "mean_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the profile features to the ratings dataframe\n",
    "\n",
    "df['level_of_education'], df['level_of_english'], df['level_of_literature'], df['level_of_history'], df['level_of_biology'], df['level_of_physics'], df['level_of_math'], df['learning_goal'], df['learning_style'] = ['', '', '', '', '', '', '', '', ''] \n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy the profile levels from learner.csv\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    target_lrn = lrn.loc[lrn.id == row.learner_id]\n",
    "    df.level_of_education.iloc[index] = target_lrn.level_of_education.values[0]\n",
    "    df.level_of_english.iloc[index] = target_lrn.level_of_english.values[0]\n",
    "    df.level_of_literature.iloc[index] = target_lrn.level_of_literature.values[0]\n",
    "    df.level_of_history.iloc[index] = target_lrn.level_of_history.values[0]\n",
    "    df.level_of_biology.iloc[index] = target_lrn.level_of_biology.values[0]\n",
    "    df.level_of_physics.iloc[index] = target_lrn.level_of_physics.values[0]\n",
    "    df.level_of_math.iloc[index] = target_lrn.level_of_math.values[0]\n",
    "    df.learning_goal.iloc[index] = target_lrn.learning_goal.values[0]\n",
    "    df.learning_style.iloc[index] = target_lrn.learning_style.values[0]\n",
    "#     print(target_lrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rating mean grouped by levels\n",
    "\n",
    "mean_education = df.groupby(['level_of_education'])['rating'].mean()\n",
    "mean_english = df.groupby(['level_of_english'])['rating'].mean()\n",
    "mean_literature = df.groupby(['level_of_literature'])['rating'].mean()\n",
    "mean_history = df.groupby(['level_of_history'])['rating'].mean()\n",
    "mean_biology = df.groupby(['level_of_biology'])['rating'].mean()\n",
    "mean_physics = df.groupby(['level_of_physics'])['rating'].mean()\n",
    "mean_math = df.groupby(['level_of_math'])['rating'].mean()\n",
    "mean_lgoal = df.groupby(['learning_goal'])['rating'].mean()\n",
    "mean_lstyle = df.groupby(['learning_style'])['rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Means:\\n' + str(mean_education) + '\\n\\n' + str(mean_english) + '\\n\\n' + str(mean_literature) + '\\n\\n' + str(mean_history) + '\\n\\n' + str(mean_biology) + '\\n\\n' + str(mean_physics) + '\\n\\n' + str(mean_math)+ '\\n\\n' + str(mean_lgoal)+ '\\n\\n' + str(mean_lstyle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('../data/ratings_context.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the item's rating mean\n",
    "\n",
    "# df.rating = pd.to_numeric(df.rating, downcast = 'integer', errors='coerce')\n",
    "\n",
    "items_mean = df.groupby(['movie_id'])['rating'].mean()\n",
    "overall_mean = items_mean.mean()\n",
    "\n",
    "overall_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the item bias\n",
    "\n",
    "items_bias = items_mean - overall_mean\n",
    "\n",
    "overall_bias = items_bias.mean()\n",
    "\n",
    "overall_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #get specific user bias (baseline)\n",
    "\n",
    "# def user_bias(user):\n",
    "#     u_index = users_mean.index.get_loc(user) #get integer index through the label index\n",
    "#     u_mean = users_mean[u_index] #get user mean\n",
    "#     u_bias = u_mean - overall_mean #compute user bias\n",
    "#     return(u_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the bias on dataframe\n",
    "df['profile_bias'] = np.nan\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row.level_of_literature == 'HL':\n",
    "        df.profile_bias.iloc[index] = float(items_mean[row.movie_id]) - float(mean_literature[0])\n",
    "    elif row.level_of_literature == 'LL':\n",
    "        df.profile_bias.iloc[index] = float(items_mean[row.movie_id]) - float(mean_literature[1])\n",
    "    elif row.level_of_literature == 'ML':\n",
    "        df.profile_bias.iloc[index] = float(items_mean[row.movie_id]) - float(mean_literature[2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the contextual factor bias CAMF-CCI (na verdade eu teria que fazer a influencia de cada \n",
    "# valor contextual sobre o item e nao de cada categoria de contexto sobre o item CAMF-CCI Ã© uma adap de CAMF-CI)\n",
    "\n",
    "profile_bias = df.groupby(['learner_id'])['profile_bias'].mean()\n",
    "\n",
    "total_profile_bias = items_mean.mean()+profile_bias.mean()+items_bias.mean()\n",
    "\n",
    "total_profile_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('../data/ratings_bias.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load from here to use the already saved ratings_bias.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ignore if already loaded\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users = 78 | Number of movies = 405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2426, 17)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if there is a ratings_bias.csv file\n",
    "df = pd.read_csv('../data/ratings_bias.csv', sep=',', skipinitialspace=True)\n",
    "\n",
    "n_users = df.learner_id.unique().shape[0]\n",
    "n_items = df.movie_id.unique().shape[0]\n",
    "\n",
    "print('Number of users = ' + str(n_users) + ' | Number of movies = ' + str(n_items))\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum learner_id in this list is= 111\n"
     ]
    }
   ],
   "source": [
    "#ignore if already loaded\n",
    "id_max = df.sort_values(by=['learner_id'], ascending=False).head(n=1)\n",
    "\n",
    "id_max = int(id_max.learner_id)\n",
    "\n",
    "print('The maximum learner_id in this list is= ' + str(id_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ignore if already loaded\n",
    "mv = pd.read_csv('../data/movie.csv', sep=',', skipinitialspace=True)\n",
    "\n",
    "df['movie_knowledge_area'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ignore if already loaded\n",
    "lrn = pd.read_csv('../data/learner.csv', sep=',', skipinitialspace=True)\n",
    "\n",
    "lrn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(df,test_size=0.25)\n",
    "\n",
    "train_data = pd.DataFrame(train_data)\n",
    "test_data = pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the specific biases\n",
    "# def biases(B):\n",
    "#items mean\n",
    "train_mean = train_data.groupby(['movie_id'])['rating'].mean()\n",
    "test_mean = test_data.groupby(['movie_id'])['rating'].mean()\n",
    "\n",
    "#profile bias\n",
    "train_pbias = train_data.groupby(['learner_id'])['profile_bias'].mean()\n",
    "test_pbias = test_data.groupby(['learner_id'])['profile_bias'].mean()\n",
    "\n",
    "#items bias\n",
    "train_bias = train_mean - train_mean.mean()\n",
    "test_bias = test_mean - test_mean.mean()\n",
    "\n",
    "#     if B =='train':\n",
    "#         return train_mean.mean()+train_pbias.mean()+train_bias.mean()\n",
    "#     elif B =='test':\n",
    "#         return test_mean.mean()+test_pbias.mean()+test_bias.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get whole dataset bias\n",
    "\n",
    "#items_mean\n",
    "items_mean = df.groupby(['movie_id'])['rating'].mean()\n",
    "overall_mean = items_mean.mean()\n",
    "\n",
    "#profile_bias\n",
    "profile_bias = df.groupby(['learner_id'])['profile_bias'].mean()\n",
    "\n",
    "#item_bias\n",
    "items_bias = items_mean - overall_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test matrix\n",
    "R = np.zeros((id_max, n_items))\n",
    "for line in train_data.itertuples():\n",
    "    R[line[6]-1, line[5]-1] = line[2]\n",
    "\n",
    "T = np.zeros((id_max, n_items))\n",
    "for line in test_data.itertuples():\n",
    "    T[line[6]-1, line[5]-1] = line[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Index matrix for training data\n",
    "I = R.copy()\n",
    "I[I > 0] = 1\n",
    "I[I == 0] = 0\n",
    "\n",
    "# Index matrix for test data\n",
    "I2 = T.copy()\n",
    "I2[I2 > 0] = 1\n",
    "I2[I2 == 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict the unknown ratings through the dot product of the latent features for users and items \n",
    "def prediction(P,Q,IM,UB,IB):\n",
    "    return (np.dot(P.T,Q)+IM+UB+IB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lmbda = 0.9 # Regularisation weight\n",
    "k = 8  # Dimensionality of the latent feature space\n",
    "m, n = R.shape  # Number of users and items\n",
    "n_epochs = 300  # Number of epochs\n",
    "gamma=0.009 # Learning rate\n",
    "\n",
    "P = 3 * np.random.rand(k,m) # Latent user feature matrix\n",
    "Q = 3 * np.random.rand(k,n) # Latent movie feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the RMSE\n",
    "def rmse(I,R,Q,P,B):\n",
    "    return np.sqrt(np.sum((I * (R - (np.dot(P.T,Q)+biases(B)))**2)/len(R[R > 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate MAE\n",
    "def mae(I,R,Q,P,B):\n",
    "    return np.sum(abs((I * (R - (np.dot(P.T,Q)+biases(B)))/len(R[R > 0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/300] Train error:7.80942030117-->Test error:7.75187579749\n",
      "Epoch[2/300] Train error:6.91070761541-->Test error:6.84269015401\n",
      "Epoch[3/300] Train error:6.48791909724-->Test error:6.41598834778\n",
      "Epoch[4/300] Train error:6.15795463639-->Test error:6.08403408693\n",
      "Epoch[5/300] Train error:5.90411930603-->Test error:5.82917305261\n",
      "Epoch[6/300] Train error:5.69479392515-->Test error:5.61916468035\n",
      "Epoch[7/300] Train error:5.49049807296-->Test error:5.41445859587\n",
      "Epoch[8/300] Train error:5.30730529647-->Test error:5.23101504483\n",
      "Epoch[9/300] Train error:5.14621922707-->Test error:5.06975421816\n",
      "Epoch[10/300] Train error:4.996305182-->Test error:4.91965332882\n",
      "Epoch[11/300] Train error:4.85028490347-->Test error:4.77345247707\n",
      "Epoch[12/300] Train error:4.7118931724-->Test error:4.63489194431\n",
      "Epoch[13/300] Train error:4.58206681023-->Test error:4.50489206794\n",
      "Epoch[14/300] Train error:4.45882606934-->Test error:4.38147289197\n",
      "Epoch[15/300] Train error:4.34029682484-->Test error:4.26276189165\n",
      "Epoch[16/300] Train error:4.22613149131-->Test error:4.1484137299\n",
      "Epoch[17/300] Train error:4.11709393183-->Test error:4.03920142761\n",
      "Epoch[18/300] Train error:4.01281775801-->Test error:3.93475429278\n",
      "Epoch[19/300] Train error:3.91232783084-->Test error:3.83410609189\n",
      "Epoch[20/300] Train error:3.81552118934-->Test error:3.73714273918\n",
      "Epoch[21/300] Train error:3.72250498324-->Test error:3.6439800563\n",
      "Epoch[22/300] Train error:3.63308727024-->Test error:3.55442116397\n",
      "Epoch[23/300] Train error:3.54693813524-->Test error:3.46814262339\n",
      "Epoch[24/300] Train error:3.46387516994-->Test error:3.38495419755\n",
      "Epoch[25/300] Train error:3.3838473097-->Test error:3.30480141858\n",
      "Epoch[26/300] Train error:3.30673572592-->Test error:3.22756452325\n",
      "Epoch[27/300] Train error:3.23234535457-->Test error:3.15304849581\n",
      "Epoch[28/300] Train error:3.16055297203-->Test error:3.08113166988\n",
      "Epoch[29/300] Train error:3.09127378606-->Test error:3.0117297377\n",
      "Epoch[30/300] Train error:3.0244044552-->Test error:2.94473966139\n",
      "Epoch[31/300] Train error:2.95984480889-->Test error:2.8800613995\n",
      "Epoch[32/300] Train error:2.89748344433-->Test error:2.81758402929\n",
      "Epoch[33/300] Train error:2.8372370295-->Test error:2.75722759657\n",
      "Epoch[34/300] Train error:2.77903317782-->Test error:2.69892062512\n",
      "Epoch[35/300] Train error:2.7227962395-->Test error:2.64258250877\n",
      "Epoch[36/300] Train error:2.66843895994-->Test error:2.58812827393\n",
      "Epoch[37/300] Train error:2.61588995979-->Test error:2.53548526596\n",
      "Epoch[38/300] Train error:2.56507650335-->Test error:2.48458131098\n",
      "Epoch[39/300] Train error:2.51592957406-->Test error:2.43534667094\n",
      "Epoch[40/300] Train error:2.46838301956-->Test error:2.38771362893\n",
      "Epoch[41/300] Train error:2.42237800502-->Test error:2.34162451829\n",
      "Epoch[42/300] Train error:2.37786031715-->Test error:2.29703157127\n",
      "Epoch[43/300] Train error:2.33477514203-->Test error:2.25387663858\n",
      "Epoch[44/300] Train error:2.29306307852-->Test error:2.21209669242\n",
      "Epoch[45/300] Train error:2.25266243672-->Test error:2.17162947249\n",
      "Epoch[46/300] Train error:2.21352416598-->Test error:2.13242597919\n",
      "Epoch[47/300] Train error:2.17561211521-->Test error:2.09445020373\n",
      "Epoch[48/300] Train error:2.13887967134-->Test error:2.05765569109\n",
      "Epoch[49/300] Train error:2.10329162921-->Test error:2.02200748813\n",
      "Epoch[50/300] Train error:2.06881313405-->Test error:1.98747074958\n",
      "Epoch[51/300] Train error:2.03540601597-->Test error:1.95400695701\n",
      "Epoch[52/300] Train error:2.00301686902-->Test error:1.921562536\n",
      "Epoch[53/300] Train error:1.97161219843-->Test error:1.89010447343\n",
      "Epoch[54/300] Train error:1.94116933076-->Test error:1.85961021483\n",
      "Epoch[55/300] Train error:1.91165418891-->Test error:1.83004491498\n",
      "Epoch[56/300] Train error:1.88302411811-->Test error:1.8013661466\n",
      "Epoch[57/300] Train error:1.85524179534-->Test error:1.77353704724\n",
      "Epoch[58/300] Train error:1.82828498596-->Test error:1.74653470157\n",
      "Epoch[59/300] Train error:1.80212178626-->Test error:1.72032701721\n",
      "Epoch[60/300] Train error:1.77671834011-->Test error:1.69488121935\n",
      "Epoch[61/300] Train error:1.75205182164-->Test error:1.67017395881\n",
      "Epoch[62/300] Train error:1.7281004363-->Test error:1.6461832046\n",
      "Epoch[63/300] Train error:1.70483243246-->Test error:1.62288171376\n",
      "Epoch[64/300] Train error:1.6822236701-->Test error:1.60024238327\n",
      "Epoch[65/300] Train error:1.66025913553-->Test error:1.57825314039\n",
      "Epoch[66/300] Train error:1.63890620738-->Test error:1.55687620291\n",
      "Epoch[67/300] Train error:1.61813740216-->Test error:1.53608414996\n",
      "Epoch[68/300] Train error:1.59794325811-->Test error:1.51586725025\n",
      "Epoch[69/300] Train error:1.57830072243-->Test error:1.49620170954\n",
      "Epoch[70/300] Train error:1.55919595538-->Test error:1.47707537574\n",
      "Epoch[71/300] Train error:1.540614194-->Test error:1.4584737161\n",
      "Epoch[72/300] Train error:1.52253576132-->Test error:1.44037809163\n",
      "Epoch[73/300] Train error:1.50493509028-->Test error:1.42276142709\n",
      "Epoch[74/300] Train error:1.48780024254-->Test error:1.40561084715\n",
      "Epoch[75/300] Train error:1.47111810017-->Test error:1.38892048925\n",
      "Epoch[76/300] Train error:1.45487721016-->Test error:1.37267200312\n",
      "Epoch[77/300] Train error:1.43906894063-->Test error:1.35685632019\n",
      "Epoch[78/300] Train error:1.42367376766-->Test error:1.34145414147\n",
      "Epoch[79/300] Train error:1.40868407967-->Test error:1.32645758221\n",
      "Epoch[80/300] Train error:1.39409358195-->Test error:1.31186032658\n",
      "Epoch[81/300] Train error:1.37988502108-->Test error:1.29764554316\n",
      "Epoch[82/300] Train error:1.36603685479-->Test error:1.28379142242\n",
      "Epoch[83/300] Train error:1.35254489174-->Test error:1.27029364192\n",
      "Epoch[84/300] Train error:1.33941134353-->Test error:1.25715493073\n",
      "Epoch[85/300] Train error:1.32662370151-->Test error:1.2443624197\n",
      "Epoch[86/300] Train error:1.31416525823-->Test error:1.23189997809\n",
      "Epoch[87/300] Train error:1.30202296449-->Test error:1.21976004158\n",
      "Epoch[88/300] Train error:1.29018569791-->Test error:1.20792510519\n",
      "Epoch[89/300] Train error:1.27865011368-->Test error:1.19639190703\n",
      "Epoch[90/300] Train error:1.26741406252-->Test error:1.18515824954\n",
      "Epoch[91/300] Train error:1.25646783164-->Test error:1.17421455858\n",
      "Epoch[92/300] Train error:1.24580124791-->Test error:1.16355061281\n",
      "Epoch[93/300] Train error:1.2354086831-->Test error:1.15316088025\n",
      "Epoch[94/300] Train error:1.22528549571-->Test error:1.14304078955\n",
      "Epoch[95/300] Train error:1.21542530861-->Test error:1.13318404133\n",
      "Epoch[96/300] Train error:1.2058176821-->Test error:1.12358020426\n",
      "Epoch[97/300] Train error:1.19645057296-->Test error:1.11421688531\n",
      "Epoch[98/300] Train error:1.18731670483-->Test error:1.10508672238\n",
      "Epoch[99/300] Train error:1.17841311741-->Test error:1.0961869208\n",
      "Epoch[100/300] Train error:1.16972573064-->Test error:1.0875037846\n",
      "Epoch[101/300] Train error:1.16124143062-->Test error:1.07902396097\n",
      "Epoch[102/300] Train error:1.15296475949-->Test error:1.07075194744\n",
      "Epoch[103/300] Train error:1.1448903725-->Test error:1.06268221159\n",
      "Epoch[104/300] Train error:1.13700992027-->Test error:1.05480640083\n",
      "Epoch[105/300] Train error:1.12931606201-->Test error:1.04711739723\n",
      "Epoch[106/300] Train error:1.12180678523-->Test error:1.03961330429\n",
      "Epoch[107/300] Train error:1.11447155328-->Test error:1.03228356876\n",
      "Epoch[108/300] Train error:1.10731086694-->Test error:1.02512842748\n",
      "Epoch[109/300] Train error:1.10032142729-->Test error:1.01814453546\n",
      "Epoch[110/300] Train error:1.09349322533-->Test error:1.01132189506\n",
      "Epoch[111/300] Train error:1.08683472227-->Test error:1.00466902203\n",
      "Epoch[112/300] Train error:1.0803334652-->Test error:0.998173719256\n",
      "Epoch[113/300] Train error:1.07398158927-->Test error:0.991827991813\n",
      "Epoch[114/300] Train error:1.06777654692-->Test error:0.985628881524\n",
      "Epoch[115/300] Train error:1.06172065847-->Test error:0.979575910755\n",
      "Epoch[116/300] Train error:1.05580534373-->Test error:0.973663601526\n",
      "Epoch[117/300] Train error:1.05002242804-->Test error:0.967883969145\n",
      "Epoch[118/300] Train error:1.04436834093-->Test error:0.962233456052\n",
      "Epoch[119/300] Train error:1.03884599084-->Test error:0.956714908289\n",
      "Epoch[120/300] Train error:1.03344419001-->Test error:0.951317018108\n",
      "Epoch[121/300] Train error:1.02816190821-->Test error:0.946038701805\n",
      "Epoch[122/300] Train error:1.02299949185-->Test error:0.940880408157\n",
      "Epoch[123/300] Train error:1.0179516256-->Test error:0.935836748182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[124/300] Train error:1.0130218949-->Test error:0.930911294958\n",
      "Epoch[125/300] Train error:1.00820688812-->Test error:0.926100942675\n",
      "Epoch[126/300] Train error:1.00350036409-->Test error:0.921398928044\n",
      "Epoch[127/300] Train error:0.998900707173-->Test error:0.91680376035\n",
      "Epoch[128/300] Train error:0.994402102808-->Test error:0.912309707015\n",
      "Epoch[129/300] Train error:0.99000435014-->Test error:0.907916616865\n",
      "Epoch[130/300] Train error:0.985704529765-->Test error:0.903621547585\n",
      "Epoch[131/300] Train error:0.981503477379-->Test error:0.899425283546\n",
      "Epoch[132/300] Train error:0.977402488787-->Test error:0.895329103755\n",
      "Epoch[133/300] Train error:0.973399813167-->Test error:0.891331174443\n",
      "Epoch[134/300] Train error:0.969491683204-->Test error:0.887427840518\n",
      "Epoch[135/300] Train error:0.965671114552-->Test error:0.883612193034\n",
      "Epoch[136/300] Train error:0.961935619491-->Test error:0.87988174364\n",
      "Epoch[137/300] Train error:0.958287886484-->Test error:0.876239140865\n",
      "Epoch[138/300] Train error:0.954723973327-->Test error:0.872680559202\n",
      "Epoch[139/300] Train error:0.951239437921-->Test error:0.869201423274\n",
      "Epoch[140/300] Train error:0.947836620374-->Test error:0.865804018284\n",
      "Epoch[141/300] Train error:0.944513028866-->Test error:0.862485886772\n",
      "Epoch[142/300] Train error:0.941269477513-->Test error:0.859247843823\n",
      "Epoch[143/300] Train error:0.938099371953-->Test error:0.85608327122\n",
      "Epoch[144/300] Train error:0.935006194672-->Test error:0.852995639475\n",
      "Epoch[145/300] Train error:0.931994646646-->Test error:0.849989752401\n",
      "Epoch[146/300] Train error:0.929056377339-->Test error:0.847057206713\n",
      "Epoch[147/300] Train error:0.926184205941-->Test error:0.844190780188\n",
      "Epoch[148/300] Train error:0.923372051488-->Test error:0.841384152522\n",
      "Epoch[149/300] Train error:0.920622254047-->Test error:0.838639193502\n",
      "Epoch[150/300] Train error:0.917934931252-->Test error:0.835956630668\n",
      "Epoch[151/300] Train error:0.915308889798-->Test error:0.833335546291\n",
      "Epoch[152/300] Train error:0.912742988468-->Test error:0.830774649811\n",
      "Epoch[153/300] Train error:0.910236245527-->Test error:0.828273627329\n",
      "Epoch[154/300] Train error:0.907785664837-->Test error:0.825831232626\n",
      "Epoch[155/300] Train error:0.905388834678-->Test error:0.823442606701\n",
      "Epoch[156/300] Train error:0.903044382036-->Test error:0.821106393408\n",
      "Epoch[157/300] Train error:0.900750299313-->Test error:0.818820550085\n",
      "Epoch[158/300] Train error:0.89850828246-->Test error:0.81658675528\n",
      "Epoch[159/300] Train error:0.896314250236-->Test error:0.814400951185\n",
      "Epoch[160/300] Train error:0.894163890776-->Test error:0.812258772623\n",
      "Epoch[161/300] Train error:0.892059160248-->Test error:0.810162170204\n",
      "Epoch[162/300] Train error:0.889999274071-->Test error:0.808110291712\n",
      "Epoch[163/300] Train error:0.887984299004-->Test error:0.806103320555\n",
      "Epoch[164/300] Train error:0.886012227643-->Test error:0.804139268583\n",
      "Epoch[165/300] Train error:0.884081153038-->Test error:0.802216206324\n",
      "Epoch[166/300] Train error:0.882189706371-->Test error:0.800332724087\n",
      "Epoch[167/300] Train error:0.880342667693-->Test error:0.798493599937\n",
      "Epoch[168/300] Train error:0.878535832829-->Test error:0.796694676201\n",
      "Epoch[169/300] Train error:0.876768005376-->Test error:0.794934170769\n",
      "Epoch[170/300] Train error:0.875036442698-->Test error:0.793209913758\n",
      "Epoch[171/300] Train error:0.873342912956-->Test error:0.791523656997\n",
      "Epoch[172/300] Train error:0.871684012306-->Test error:0.789872060981\n",
      "Epoch[173/300] Train error:0.870058174774-->Test error:0.788253488029\n",
      "Epoch[174/300] Train error:0.868461919146-->Test error:0.786663964624\n",
      "Epoch[175/300] Train error:0.866898408801-->Test error:0.785107205823\n",
      "Epoch[176/300] Train error:0.865366837133-->Test error:0.783582384997\n",
      "Epoch[177/300] Train error:0.863864413017-->Test error:0.782086699691\n",
      "Epoch[178/300] Train error:0.862391792447-->Test error:0.780620791863\n",
      "Epoch[179/300] Train error:0.860947050381-->Test error:0.779182743225\n",
      "Epoch[180/300] Train error:0.859529703142-->Test error:0.777772112263\n",
      "Epoch[181/300] Train error:0.858138634832-->Test error:0.776387762075\n",
      "Epoch[182/300] Train error:0.856773922554-->Test error:0.775030469694\n",
      "Epoch[183/300] Train error:0.855434089457-->Test error:0.77369907379\n",
      "Epoch[184/300] Train error:0.854117282004-->Test error:0.772390680152\n",
      "Epoch[185/300] Train error:0.852825174768-->Test error:0.77110692746\n",
      "Epoch[186/300] Train error:0.85155783489-->Test error:0.769847951256\n",
      "Epoch[187/300] Train error:0.850311992985-->Test error:0.768610423936\n",
      "Epoch[188/300] Train error:0.849087323072-->Test error:0.767394480634\n",
      "Epoch[189/300] Train error:0.847884589882-->Test error:0.766201415327\n",
      "Epoch[190/300] Train error:0.846703024154-->Test error:0.765029457908\n",
      "Epoch[191/300] Train error:0.845544969369-->Test error:0.76388096368\n",
      "Epoch[192/300] Train error:0.84440816873-->Test error:0.762753670367\n",
      "Epoch[193/300] Train error:0.8432923446-->Test error:0.761647267267\n",
      "Epoch[194/300] Train error:0.842196071221-->Test error:0.760560360433\n",
      "Epoch[195/300] Train error:0.841118044409-->Test error:0.759491628331\n",
      "Epoch[196/300] Train error:0.84005934727-->Test error:0.758442189\n",
      "Epoch[197/300] Train error:0.83901908826-->Test error:0.757411134123\n",
      "Epoch[198/300] Train error:0.837996792793-->Test error:0.756398021429\n",
      "Epoch[199/300] Train error:0.836991702023-->Test error:0.755402063396\n",
      "Epoch[200/300] Train error:0.836003717258-->Test error:0.754423171832\n",
      "Epoch[201/300] Train error:0.835034558067-->Test error:0.753463037245\n",
      "Epoch[202/300] Train error:0.834083531666-->Test error:0.75252098363\n",
      "Epoch[203/300] Train error:0.8331503048-->Test error:0.751596629211\n",
      "Epoch[204/300] Train error:0.832235757786-->Test error:0.750690860837\n",
      "Epoch[205/300] Train error:0.83133764572-->Test error:0.749801476065\n",
      "Epoch[206/300] Train error:0.830455972418-->Test error:0.748928480013\n",
      "Epoch[207/300] Train error:0.829589622615-->Test error:0.748070755962\n",
      "Epoch[208/300] Train error:0.828738524792-->Test error:0.74722823261\n",
      "Epoch[209/300] Train error:0.827902140564-->Test error:0.74640037178\n",
      "Epoch[210/300] Train error:0.827082513757-->Test error:0.745587916338\n",
      "Epoch[211/300] Train error:0.826279603773-->Test error:0.74479170177\n",
      "Epoch[212/300] Train error:0.825491605887-->Test error:0.744010327531\n",
      "Epoch[213/300] Train error:0.824718672968-->Test error:0.743244684092\n",
      "Epoch[214/300] Train error:0.823960220123-->Test error:0.742493768787\n",
      "Epoch[215/300] Train error:0.823214226032-->Test error:0.741755246757\n",
      "Epoch[216/300] Train error:0.822481776804-->Test error:0.741030188962\n",
      "Epoch[217/300] Train error:0.82176381761-->Test error:0.740319557602\n",
      "Epoch[218/300] Train error:0.821058917285-->Test error:0.739621911343\n",
      "Epoch[219/300] Train error:0.820367820576-->Test error:0.738938029182\n",
      "Epoch[220/300] Train error:0.81969048811-->Test error:0.738267872663\n",
      "Epoch[221/300] Train error:0.819025479477-->Test error:0.737609991241\n",
      "Epoch[222/300] Train error:0.818373231286-->Test error:0.736964820539\n",
      "Epoch[223/300] Train error:0.817732181174-->Test error:0.736330807071\n",
      "Epoch[224/300] Train error:0.817103535486-->Test error:0.735709147733\n",
      "Epoch[225/300] Train error:0.816485934581-->Test error:0.735098482857\n",
      "Epoch[226/300] Train error:0.815878340703-->Test error:0.734497779002\n",
      "Epoch[227/300] Train error:0.815282656615-->Test error:0.733908725455\n",
      "Epoch[228/300] Train error:0.814697167201-->Test error:0.733329803562\n",
      "Epoch[229/300] Train error:0.814123315137-->Test error:0.732762524879\n",
      "Epoch[230/300] Train error:0.813559306636-->Test error:0.73220510902\n",
      "Epoch[231/300] Train error:0.813005993508-->Test error:0.731658333899\n",
      "Epoch[232/300] Train error:0.812463000501-->Test error:0.73112183612\n",
      "Epoch[233/300] Train error:0.811929676307-->Test error:0.73059496194\n",
      "Epoch[234/300] Train error:0.811405332933-->Test error:0.730077061875\n",
      "Epoch[235/300] Train error:0.810890317838-->Test error:0.72956844666\n",
      "Epoch[236/300] Train error:0.810384200054-->Test error:0.729068682403\n",
      "Epoch[237/300] Train error:0.809885635284-->Test error:0.728576410293\n",
      "Epoch[238/300] Train error:0.809394774627-->Test error:0.728091776803\n",
      "Epoch[239/300] Train error:0.808912437444-->Test error:0.727615631389\n",
      "Epoch[240/300] Train error:0.808438567226-->Test error:0.727147907493\n",
      "Epoch[241/300] Train error:0.807971574489-->Test error:0.726687016568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[242/300] Train error:0.807511805294-->Test error:0.726233306633\n",
      "Epoch[243/300] Train error:0.807059400524-->Test error:0.725786919091\n",
      "Epoch[244/300] Train error:0.806613834171-->Test error:0.725347329411\n",
      "Epoch[245/300] Train error:0.806174893393-->Test error:0.724914327531\n",
      "Epoch[246/300] Train error:0.805742469478-->Test error:0.724487807794\n",
      "Epoch[247/300] Train error:0.805316555936-->Test error:0.724067758749\n",
      "Epoch[248/300] Train error:0.804897224012-->Test error:0.723654251528\n",
      "Epoch[249/300] Train error:0.804484305271-->Test error:0.723247118973\n",
      "Epoch[250/300] Train error:0.804077986326-->Test error:0.722846554529\n",
      "Epoch[251/300] Train error:0.80367749505-->Test error:0.722451744724\n",
      "Epoch[252/300] Train error:0.803283619516-->Test error:0.722063490077\n",
      "Epoch[253/300] Train error:0.802896374936-->Test error:0.721681833497\n",
      "Epoch[254/300] Train error:0.802515188274-->Test error:0.721306220502\n",
      "Epoch[255/300] Train error:0.802139676258-->Test error:0.720936261554\n",
      "Epoch[256/300] Train error:0.801771330877-->Test error:0.720573392679\n",
      "Epoch[257/300] Train error:0.801409059917-->Test error:0.720216562342\n",
      "Epoch[258/300] Train error:0.801052717627-->Test error:0.719865632602\n",
      "Epoch[259/300] Train error:0.800701990692-->Test error:0.71952028162\n",
      "Epoch[260/300] Train error:0.80035682515-->Test error:0.719180454207\n",
      "Epoch[261/300] Train error:0.800016803821-->Test error:0.71884575495\n",
      "Epoch[262/300] Train error:0.799681578061-->Test error:0.718515815256\n",
      "Epoch[263/300] Train error:0.799351994281-->Test error:0.718191478574\n",
      "Epoch[264/300] Train error:0.799027543298-->Test error:0.717872237808\n",
      "Epoch[265/300] Train error:0.798708503721-->Test error:0.717558377919\n",
      "Epoch[266/300] Train error:0.798395700164-->Test error:0.717250718972\n",
      "Epoch[267/300] Train error:0.798087230577-->Test error:0.716947315941\n",
      "Epoch[268/300] Train error:0.797783155029-->Test error:0.716648206567\n",
      "Epoch[269/300] Train error:0.797483553147-->Test error:0.716353536492\n",
      "Epoch[270/300] Train error:0.797189789645-->Test error:0.716064663325\n",
      "Epoch[271/300] Train error:0.796900029492-->Test error:0.715779581158\n",
      "Epoch[272/300] Train error:0.796614159435-->Test error:0.71549798527\n",
      "Epoch[273/300] Train error:0.796332592054-->Test error:0.715220675001\n",
      "Epoch[274/300] Train error:0.796054976915-->Test error:0.71494731167\n",
      "Epoch[275/300] Train error:0.795781703471-->Test error:0.714678270285\n",
      "Epoch[276/300] Train error:0.795513309059-->Test error:0.714414080408\n",
      "Epoch[277/300] Train error:0.795249502731-->Test error:0.714154451074\n",
      "Epoch[278/300] Train error:0.794990567549-->Test error:0.713899665909\n",
      "Epoch[279/300] Train error:0.7947351971-->Test error:0.713648419427\n",
      "Epoch[280/300] Train error:0.794483780036-->Test error:0.713401100471\n",
      "Epoch[281/300] Train error:0.794236194817-->Test error:0.7131575876\n",
      "Epoch[282/300] Train error:0.793992782972-->Test error:0.712918204917\n",
      "Epoch[283/300] Train error:0.793753153374-->Test error:0.712682572649\n",
      "Epoch[284/300] Train error:0.793517878069-->Test error:0.712451271212\n",
      "Epoch[285/300] Train error:0.793287142744-->Test error:0.712224348868\n",
      "Epoch[286/300] Train error:0.793060028336-->Test error:0.712001009763\n",
      "Epoch[287/300] Train error:0.792836172903-->Test error:0.711780913294\n",
      "Epoch[288/300] Train error:0.792615571241-->Test error:0.711564049447\n",
      "Epoch[289/300] Train error:0.792399863254-->Test error:0.711352055697\n",
      "Epoch[290/300] Train error:0.792188393492-->Test error:0.71114427614\n",
      "Epoch[291/300] Train error:0.791980628141-->Test error:0.71094017078\n",
      "Epoch[292/300] Train error:0.791775849472-->Test error:0.710739026921\n",
      "Epoch[293/300] Train error:0.791574865088-->Test error:0.710541653602\n",
      "Epoch[294/300] Train error:0.791377323854-->Test error:0.710347703569\n",
      "Epoch[295/300] Train error:0.791182595012-->Test error:0.710156543462\n",
      "Epoch[296/300] Train error:0.790990922908-->Test error:0.709968415436\n",
      "Epoch[297/300] Train error:0.790802328079-->Test error:0.70978333852\n",
      "Epoch[298/300] Train error:0.790616975886-->Test error:0.709601480921\n",
      "Epoch[299/300] Train error:0.790435129265-->Test error:0.709423105857\n",
      "Epoch[300/300] Train error:0.790256446543-->Test error:0.709247870841\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "#Only consider non-zero matrix \n",
    "users,items = R.nonzero()      \n",
    "for epoch in range(n_epochs):\n",
    "    error = 0\n",
    "    for u, i in zip(users,items):\n",
    "        e = R[u, i] - prediction(P[:,u],Q[:,i],items_mean[i+1],profile_bias[u+1],items_bias[i+1])  # Calculate error for gradient\n",
    "        P[:,u] += gamma * ( e * Q[:,i] - lmbda * P[:,u]) # Update latent user feature matrix\n",
    "        Q[:,i] += gamma * ( e * P[:,u] - lmbda * Q[:,i])  # Update latent movie feature matrix\n",
    "#         error += e\n",
    "#     train_e = abs(error/users.shape[0])\n",
    "#     test_e = abs((T - (np.dot(P.T,Q)+items_mean.mean()+profile_bias.mean()+items_bias.mean())).mean())\n",
    "#     train_rmse = rmse(I,R,Q,P,'train') # Calculate root mean squared error from train dataset\n",
    "#     test_rmse = rmse(I2,T,Q,P,'test') # Calculate root mean squared error from test dataset\n",
    "#     train_mae = mae(I,R,Q,P,'train')\n",
    "#     test_mae = mae(I2,T,Q,P,'test')\n",
    "    train_mae = mean_absolute_error(R, np.dot(P.T,Q))\n",
    "    test_mae = mean_absolute_error(T, np.dot(P.T,Q))\n",
    "    train_errors.append(train_mae)\n",
    "    test_errors.append(test_mae)\n",
    "    print(\"Epoch[\"+ str(epoch+1) + \"/\" + str(n_epochs) + \"] Train error:\" + str(train_mae) + \"-->Test error:\" + str(test_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mean_absolute_error(R, np.dot(P.T,Q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(T, np.dot(P.T,Q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAVWqXpIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd1118367f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check performance by plotting train and test errors\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(range(n_epochs), train_errors, marker='o', label='Training Data');\n",
    "plt.plot(range(n_epochs), test_errors, marker='v', label='Test Data');\n",
    "plt.title('SGD-WR Learning Curve')\n",
    "plt.xlabel('Number of Epochs');\n",
    "plt.ylabel('MAE');\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model seems to perform quite well, with a relatively low RMSE after convergence. The performance can be influenced by tweaking the hyperparameters $\\lambda$, $\\gamma$ and $k$. In order to learn more about hyperparameter tuning you can take a look at one of the previous [posts](http://online.cambridgecoding.com/notebooks/cca_admin/scanning-hyperspace-how-to-tune-machine-learning-models). \n",
    "\n",
    "Next you could compare the actual rating with the predicted rating. To do this you first calculate the prediction matrix â for that you can use ``prediction`` function you have implemented above and convert it to a dataframe for the ease of use.<img src=\"https://latex.codecogs.com/gif.latex?\\hat&space;r_{ui}=P_u^TQ_i$&space;&space;$(2)\" title=\"\\hat r_{ui}=p_u^Tq_i\" /> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate prediction matrix R_hat (low-rank approximation for R)\n",
    "R = pd.DataFrame(R)\n",
    "R_hat=pd.DataFrame(np.dot(P.T,Q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea of what you achieved, let's compare some of our predictions for user ``17`` with their actual ratings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compare true ratings of user 17 with predictions\n",
    "ratings = pd.DataFrame(data=R.loc[16,R.loc[16,:] > 0]).head(n=5)\n",
    "ratings['Prediction'] = R_hat.loc[16,R.loc[16,:] > 0]\n",
    "ratings.columns = ['Actual Rating', 'Predicted Rating']\n",
    "ratings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
